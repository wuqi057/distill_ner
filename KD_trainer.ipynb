{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# import packages and load data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import pickle\n",
                "from flair.data import Corpus\n",
                "from flair.datasets import SentenceDataset\n",
                "from sklearn.model_selection import train_test_split\n",
                "from flair.embeddings import WordEmbeddings, CharacterEmbeddings,StackedEmbeddings"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "path = '/Users/Wu/Google Drive/'\n",
                "with open(path+'data/data_news_LogitsLabel_12.7k.pickle', 'rb') as handle:\n",
                "    data_news = pickle.load(handle)\n",
                "\n",
                "with open(path+'data/data_conll_LogitsLabel_12.7k.pickle', 'rb') as handle:\n",
                "    data_conll = pickle.load(handle)\n",
                "\n",
                "data = data_news+data_conll\n",
                "\n",
                "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
                "data_dev,data_test = train_test_split(data_test, test_size=0.5, random_state=42)\n",
                "\n",
                "corpus: Corpus = Corpus(SentenceDataset(data_train),SentenceDataset(data_test),SentenceDataset(data_dev))\n",
                "tag_type = 'ner'\n",
                "\n",
                "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
                "corpus: Corpus = corpus.downsample(0.1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from KD_sequence_tagger_model import SequenceTagger\n",
                "# from flair.models import SequenceTagger\n",
                "\n",
                "embedding_types = [\n",
                "    WordEmbeddings('de'),\n",
                "    CharacterEmbeddings(),\n",
                "]\n",
                "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
                "\n",
                "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
                "                                        embeddings=embeddings,\n",
                "                                        tag_dictionary=tag_dictionary,\n",
                "                                        tag_type=tag_type,\n",
                "                                        use_crf=False,\n",
                "                                        reproject_embeddings = 100,\n",
                "                                        # use_soft_labels=True,\n",
                "                                        # use_logits = True,\n",
                "                                        )\n",
                "\n",
                "#%% train the model \n",
                "from flair.trainers import ModelTrainer\n",
                "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
                "\n",
                "trainer.train('resources/taggers/test2.5k_flair_glove',\n",
                "              learning_rate=0.1,\n",
                "              mini_batch_size=10,\n",
                "              max_epochs=15,\n",
                "              checkpoint=True,\n",
                "              )\n",
                "\n",
                "#%% continue training the model\n",
                "# checkpoint = 'resources/taggers/test/checkpoint.pt'\n",
                "# trainer = ModelTrainer.load_checkpoint(checkpoint, corpus) \n",
                "# trainer.train(path+'resources/taggers/test60ep',\n",
                "#               learning_rate=0.05,\n",
                "#               mini_batch_size=10,\n",
                "#               max_epochs=50,\n",
                "#               checkpoint=True) "
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}